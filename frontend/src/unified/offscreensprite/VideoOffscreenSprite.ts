import { MP4Clip } from '@webav/av-cliper'
import type { UnifiedTimeRange } from '@/unified/types/timeRange'
import { framesToMicroseconds } from '@/unified/utils/timeUtils'
import { BaseOffscreenSprite } from '@/unified/offscreensprite/BaseOffscreenSprite'
import type { AudioState } from '@/unified/visiblesprite/types'

// ä» BaseSprite å¤åˆ¶çš„ç±»å‹å®šä¹‰ï¼ˆç®€åŒ–ç‰ˆï¼Œå»æ‰ iterCountï¼‰
interface IAnimationOpts {
  duration: number
  delay?: number
}

type TAnimateProps = {
  x: number
  y: number
  w: number
  h: number
  angle: number
  opacity: number
}

export type TAnimationKeyFrame = Array<[number, Partial<TAnimateProps>]>

type TKeyFrameOpts = Partial<Record<`${number}%` | 'from' | 'to', Partial<TAnimateProps>>>

/**
 * è‡ªå®šä¹‰çš„VideoOffscreenSpriteç±»ï¼Œç»§æ‰¿è‡ªBaseOffscreenSprite
 * ä¸“é—¨ç”¨äºå¤„ç†è§†é¢‘ç´ æï¼Œæ·»åŠ äº†startOffsetå±æ€§å’ŒéŸ³é‡æ§åˆ¶åŠŸèƒ½
 * ä¸“æ³¨äºè§†é¢‘åˆæˆåŠŸèƒ½ï¼Œç§»é™¤äº†äº‹ä»¶ç›‘å¬
 */
export class VideoOffscreenSprite extends BaseOffscreenSprite {
  /**
   * éŸ³é¢‘çŠ¶æ€
   */
  #audioState: AudioState = {
    volume: 1,
    isMuted: false,
  }

  /**
   * è½¨é“é™éŸ³çŠ¶æ€
   */
  #isTrackMuted: boolean = false

  // ==================== åŠ¨ç”»ç›¸å…³ç§æœ‰å­—æ®µ ====================

  /**
   * åŠ¨ç”»å…³é”®å¸§æ•°æ®
   */
  #animatKeyFrame: TAnimationKeyFrame | null = null

  /**
   * åŠ¨ç”»é€‰é¡¹é…ç½®ï¼ˆç®€åŒ–ç‰ˆï¼Œå›ºå®š iterCount ä¸º 1ï¼‰
   */
  #animatOpts: (Required<IAnimationOpts> & { iterCount: 1 }) | null = null

  /**
   * æ„é€ å‡½æ•°
   * @param clip MP4Clipå®ä¾‹
   */
  constructor(clip: MP4Clip) {
    // è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
    super(clip)
  }

  // ==================== å˜é€Ÿæ¥å£ ====================

  /**
   * è®¾ç½®æ’­æ”¾é€Ÿåº¦
   * @param speed æ’­æ”¾é€Ÿåº¦å€ç‡ï¼ˆ1.0ä¸ºæ­£å¸¸é€Ÿåº¦ï¼Œ2.0ä¸º2å€é€Ÿï¼Œ0.5ä¸º0.5å€é€Ÿï¼‰
   */
  public setPlaybackRate(speed: number): void {
    if (speed <= 0) {
      throw new Error('æ’­æ”¾é€Ÿåº¦å¿…é¡»å¤§äº0')
    }

    const timeRange = this.getTimeRange()
    const { clipStartTime, clipEndTime, timelineStartTime } = timeRange
    const clipDuration = clipEndTime - clipStartTime

    if (clipDuration > 0) {
      // æ ¹æ®æ–°çš„æ’­æ”¾é€Ÿåº¦è®¡ç®—æ—¶é—´è½´ç»“æŸæ—¶é—´
      // æ—¶é—´è½´æ—¶é•¿ = ç´ ææ—¶é•¿ / æ’­æ”¾é€Ÿåº¦
      const newTimelineDuration = clipDuration / speed

      // ğŸ”§ ç¡®ä¿æ—¶é—´è½´ç»“æŸæ—¶é—´æ˜¯æ•´æ•°å¸§æ•°ï¼ˆé¿å…å°æ•°ç‚¹æ—¶é•¿æ˜¾ç¤ºï¼‰
      const newTimelineEndTime = timelineStartTime + Math.round(newTimelineDuration)

      // é€šè¿‡è®¾ç½®æ—¶é—´èŒƒå›´æ¥å®ç°æ’­æ”¾é€Ÿåº¦è°ƒæ•´
      // playbackRate ä¼šåœ¨ updateOffscreenSpriteTime() ä¸­æ ¹æ®æ—¶é—´èŒƒå›´è‡ªåŠ¨è®¡ç®—
      this.setTimeRange({
        timelineEndTime: newTimelineEndTime
      })
    }
  }


  // ==================== æ¸²æŸ“æ–¹æ³• ====================

  /**
   * è¦†å†™offscreenRenderæ–¹æ³•ï¼Œåº”ç”¨éŸ³é‡æ§åˆ¶
   * @param ctx æ¸²æŸ“ä¸Šä¸‹æ–‡
   * @param time å½“å‰æ—¶é—´ï¼ˆå¾®ç§’ï¼‰
   * @returns éŸ³é¢‘æ•°æ®å’Œå®ŒæˆçŠ¶æ€
   */
  public async offscreenRender(
    ctx: CanvasRenderingContext2D | OffscreenCanvasRenderingContext2D,
    time: number,
  ): Promise<{ audio: Float32Array[]; done: boolean }> {
    // è°ƒç”¨çˆ¶ç±»çš„offscreenRenderæ–¹æ³•è·å–éŸ³é¢‘æ•°æ®
    const renderResult = await super.offscreenRender(ctx, time)
    
    // å¦‚æœæœ‰éŸ³é¢‘æ•°æ®ï¼Œæ ¹æ®é™éŸ³çŠ¶æ€å’ŒéŸ³é‡è°ƒæ•´
    if (renderResult.audio && renderResult.audio.length > 0) {
      // è®¡ç®—å®é™…éŸ³é‡ï¼šè½¨é“é™éŸ³æˆ–ç‰‡æ®µé™éŸ³æ—¶ä¸º0ï¼Œå¦åˆ™ä½¿ç”¨å½“å‰éŸ³é‡
      const effectiveVolume =
        this.#audioState.isMuted || this.#isTrackMuted ? 0 : this.#audioState.volume

      if (effectiveVolume !== 1) {
        // å¯¹æ¯ä¸ªå£°é“çš„PCMæ•°æ®è¿›è¡ŒéŸ³é‡è°ƒæ•´
        for (const channel of renderResult.audio) {
          for (let i = 0; i < channel.length; i++) {
            channel[i] *= effectiveVolume
          }
        }
      }
    }

    return renderResult
  }

  // ==================== éŸ³é‡æ§åˆ¶æ¥å£ ====================

  /**
   * åŠ¨æ€è®¾ç½®éŸ³é‡
   * @param volume éŸ³é‡å€¼ï¼ˆ0-1ä¹‹é—´ï¼Œ0ä¸ºé™éŸ³ï¼Œ1ä¸ºæœ€å¤§éŸ³é‡ï¼‰
   */
  public setVolume(volume: number): void {
    // é™åˆ¶éŸ³é‡èŒƒå›´ 0-1
    this.#audioState.volume = Math.max(0, Math.min(1, volume))
  }

  /**
   * è®¾ç½®é™éŸ³çŠ¶æ€
   * @param muted æ˜¯å¦é™éŸ³
   */
  public setMuted(muted: boolean): void {
    this.#audioState.isMuted = muted
  }

  /**
   * é™éŸ³/å–æ¶ˆé™éŸ³åˆ‡æ¢
   * @returns åˆ‡æ¢åçš„é™éŸ³çŠ¶æ€ï¼ˆtrueä¸ºé™éŸ³ï¼Œfalseä¸ºæœ‰å£°éŸ³ï¼‰
   */
  public toggleMute(): boolean {
    this.#audioState.isMuted = !this.#audioState.isMuted
    return this.#audioState.isMuted
  }

  /**
   * è®¾ç½®å®Œæ•´çš„éŸ³é¢‘çŠ¶æ€
   * @param audioState éŸ³é¢‘çŠ¶æ€å¯¹è±¡
   */
  public setAudioState(audioState: AudioState): void {
    this.#audioState.volume = Math.max(0, Math.min(1, audioState.volume))
    this.#audioState.isMuted = audioState.isMuted
  }

  /**
   * è®¾ç½®è½¨é“é™éŸ³çŠ¶æ€
   * @param muted æ˜¯å¦é™éŸ³
   */
  public setTrackMuted(muted: boolean): void {
    this.#isTrackMuted = muted
  }

  // ==================== åŠ¨ç”»æ–¹æ³•ï¼ˆä»BaseSpriteå¤åˆ¶ï¼‰ ====================

  /**
   * ç»™ç´ ææ·»åŠ åŠ¨ç”»ï¼Œä½¿ç”¨æ–¹æ³•å‚è€ƒ css animation
   *
   * @example
   * sprite.setAnimation(
   *   {
   *     '0%': { x: 0, y: 0 },
   *     '25%': { x: 1200, y: 680 },
   *     '50%': { x: 1200, y: 0 },
   *     '75%': { x: 0, y: 680 },
   *     '100%': { x: 0, y: 0 },
   *   },
   *   { duration: 4e6 }, // iterCount å›ºå®šä¸º1ï¼Œæ— éœ€æŒ‡å®š
   * );
   *
   * @see [è§†é¢‘æ°´å°åŠ¨ç”»](https://webav-tech.github.io/WebAV/demo/2_1-concat-video)
   */
  public setAnimation(keyFrame: TKeyFrameOpts, opts: IAnimationOpts): void {
    this.#animatKeyFrame = Object.entries(keyFrame).map(([k, val]) => {
      const numK = { from: 0, to: 100 }[k] ?? Number(k.slice(0, -1))
      if (isNaN(numK) || numK > 100 || numK < 0) {
        throw Error('keyFrame must between 0~100')
      }
      return [numK / 100, val]
    }) as TAnimationKeyFrame

    this.#animatOpts = Object.assign({}, this.#animatOpts, {
      duration: opts.duration,
      delay: opts.delay ?? 0,
      iterCount: 1, // å›ºå®šä¸º1è½®ï¼Œç®€åŒ–é€»è¾‘
    })

    console.log('setAnimation', this.#animatKeyFrame, this.#animatOpts)
  }

  /**
   * å¦‚æœå½“å‰ sprite å·²è¢«è®¾ç½®åŠ¨ç”»ï¼Œå°† sprite çš„åŠ¨ç”»å±æ€§è®¾å®šåˆ°æŒ‡å®šæ—¶é—´çš„çŠ¶æ€
   */
  public animate(time: number): void {
    if (this.#animatKeyFrame == null || this.#animatOpts == null || time < this.#animatOpts.delay)
      return
    // console.log('animate', time, this.#animatKeyFrame, this.#animatOpts)
    const updateProps = linearTimeFn(time, this.#animatKeyFrame, this.#animatOpts)
    for (const k in updateProps) {
      switch (k) {
        case 'opacity':
          this.opacity = updateProps[k] as number
          break
        case 'x':
        case 'y':
        case 'w':
        case 'h':
        case 'angle':
          this.rect[k] = updateProps[k] as number
          break
      }
    }
  }

  // ==================== ä¿æŠ¤æ–¹æ³• ====================

  /**
   * æ›´æ–° OffscreenSprite çš„ time å±æ€§
   * è§†é¢‘ç´ æçš„å®šåˆ¶åŒ–å®ç°ï¼Œæ”¯æŒè§†é¢‘ç‰¹æœ‰çš„æ’­æ”¾é€Ÿåº¦è®¡ç®—
   */
  protected updateOffscreenSpriteTime(): void {
    const timeRange = this.getTimeRange()
    const { clipStartTime, clipEndTime, timelineStartTime, timelineEndTime } = timeRange

    // è®¡ç®—æ—¶é•¿å‚æ•°ï¼ˆä½¿ç”¨å¸§æ•°ï¼‰
    let durationFrames = 0
    let playbackRate = 1 // é»˜è®¤æ­£å¸¸é€Ÿåº¦

    const clipDurationFrames = clipEndTime - clipStartTime // ç´ æå†…éƒ¨è¦æ’­æ”¾çš„å¸§æ•°
    const timelineDurationFrames = timelineEndTime - timelineStartTime // åœ¨æ—¶é—´è½´ä¸Šå ç”¨çš„å¸§æ•°

    if (clipDurationFrames > 0 && timelineDurationFrames > 0) {
      // duration æ˜¯åœ¨æ—¶é—´è½´ä¸Šå ç”¨çš„å¸§æ•°
      durationFrames = timelineDurationFrames
      
      // è®¡ç®—æ’­æ”¾é€Ÿåº¦
      // playbackRate = ç´ æå†…éƒ¨æ—¶é•¿ / æ—¶é—´è½´æ—¶é•¿
      playbackRate = clipDurationFrames / timelineDurationFrames

      // ä¿®æ­£æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜ï¼Œé¿å…å‡ºç°1.00000001è¿™æ ·çš„å€¼
      // å¦‚æœéå¸¸æ¥è¿‘æ•´æ•°ï¼Œåˆ™å››èˆäº”å…¥åˆ°æœ€è¿‘çš„0.1
      const rounded = Math.round(playbackRate * 10) / 10
      if (Math.abs(playbackRate - rounded) < 0.001) {
        playbackRate = rounded
      }
    }

    // è®¾ç½® OffscreenSprite.time å±æ€§ï¼ˆè½¬æ¢ä¸ºå¾®ç§’ç»™WebAVï¼‰
    // offset: åœ¨æ—¶é—´è½´ä¸Šçš„æ’­æ”¾å¼€å§‹ä½ç½®ï¼ˆå¾®ç§’ï¼‰
    // duration: åœ¨æ—¶é—´è½´ä¸Šå ç”¨çš„æ—¶é•¿ï¼ˆå¾®ç§’ï¼‰
    // playbackRate: è§†é¢‘ç´ ææ’­æ”¾çš„é€Ÿåº¦
    this.time = {
      offset: framesToMicroseconds(timelineStartTime),
      duration: framesToMicroseconds(durationFrames),
      playbackRate: playbackRate,
    }
  }
}

/**
 * çº¿æ€§æ—¶é—´å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼Œå›ºå®šå•è½®æ’­æ”¾ï¼‰
 */
export function linearTimeFn(
  time: number,
  kf: TAnimationKeyFrame,
  opts: Required<IAnimationOpts> & { iterCount: 1 },
): Partial<TAnimateProps> {
  const offsetTime = time - opts.delay

  // ç®€åŒ–ï¼šå¦‚æœè¶…è¿‡åŠ¨ç”»æ—¶é•¿ï¼Œè¿”å›æœ€åä¸€å¸§çŠ¶æ€
  if (offsetTime > opts.duration) {
    const lastFrame = kf[kf.length - 1]
    return lastFrame ? lastFrame[1] : {}
  }

  // å¦‚æœè¿˜æ²¡å¼€å§‹ï¼Œè¿”å›ç©º
  if (offsetTime < 0) return {}

  // è®¡ç®—å½“å‰è¿›åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰
  const process = offsetTime / opts.duration
  const idx = kf.findIndex((it) => it[0] >= process)
  if (idx === -1) return {}

  const startState = kf[idx - 1]
  const nextState = kf[idx]
  const nextFrame = nextState[1]
  if (startState == null) return nextFrame
  const startFrame = startState[1]

  const rs: Partial<TAnimateProps> = {}
  // ä»‹äºä¸¤ä¸ªFrameçŠ¶æ€é—´çš„è¿›åº¦
  const stateProcess = (process - startState[0]) / (nextState[0] - startState[0])
  for (const prop in nextFrame) {
    const p = prop as keyof TAnimateProps
    if (startFrame[p] == null) continue
    // @ts-expect-error
      
    rs[p] = (nextFrame[p] - startFrame[p]) * stateProcess + startFrame[p]
  }

  return rs
}
